const { VertexAI } = require('@google-cloud/vertexai');


const ModelSelector = require('./ModelSelector');
const winston = require('winston');

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.json()
  ),
  transports: [new winston.transports.Console()]
});

class VertexAIClient {
  constructor() {
    this.projectId = process.env.GOOGLE_CLOUD_PROJECT_ID || 'aiduxcare-stt-20250706';
    this.location = process.env.VERTEX_AI_LOCATION || 'us-east1';
    this.defaultModel = process.env.VERTEX_AI_MODEL || 'gemini-2.5-flash'; // Modelo balanceado por defecto
    
    // Inicializar ModelSelector para optimizaci√≥n inteligente
    this.modelSelector = new ModelSelector();
    
    // Inicializar cliente Vertex AI
    this.vertexAI = new VertexAI({
      project: this.projectId,
      location: this.location
    });
    
    logger.info('üöÄ VERTEXAI CLIENT INICIALIZADO CON OPTIMIZACI√ìN DE COSTOS', {
      proyecto: this.projectId,
      region: this.location,
      modeloPorDefecto: this.defaultModel
    });
  }

  /**
   * Procesa transcripci√≥n m√©dica con optimizaci√≥n basada en evidencia emp√≠rica
   * @param {string} transcription - Transcripci√≥n m√©dica
   * @param {string} prompt - Prompt generado
   * @param {Object} options - Opciones de procesamiento
   * @returns {Promise<Object>} Respuesta procesada con informaci√≥n de optimizaci√≥n
   */
  async processTranscription(transcription, prompt, options = {}) {
    logger.info('üß† INICIANDO PROCESAMIENTO CON OPTIMIZACI√ìN DE COSTOS');
    
    try {
      // Seleccionar modelo √≥ptimo basado en evidencia emp√≠rica
      let modelSelection;
      
      if (options.forceModel) {
        // Forzar modelo espec√≠fico (para testing)
        modelSelection = this.modelSelector.forceModel(options.forceModel);
      } else {
        // Selecci√≥n autom√°tica basada en evidencia
        modelSelection = this.modelSelector.selectOptimalModel(transcription, options);
      }
      
      logger.info('‚úÖ MODELO SELECCIONADO:', {
        modelo: modelSelection.selectedModel,
        razonamiento: modelSelection.reasoning,
        ahorro: modelSelection.costAnalysis?.savingsVsPro || 'N/A'
      });

      // Procesar con el modelo seleccionado
      const result = await this.processWithModel(
        transcription,
        prompt,
        modelSelection.selectedModel,
        options
      );

      // Enriquecer respuesta con informaci√≥n de optimizaci√≥n
      result.costOptimization = {
        modelUsed: modelSelection.selectedModel,
        redFlagsDetected: modelSelection.redFlagsDetected,
        reasoning: modelSelection.reasoning,
        costAnalysis: modelSelection.costAnalysis,
        empiricalBasis: modelSelection.empiricalBasis || 'Basado en evaluaci√≥n emp√≠rica',
        timestamp: modelSelection.timestamp
      };

      return result;

    } catch (error) {
      logger.error('‚ùå ERROR EN PROCESAMIENTO:', error);
      throw error;
    }
  }

  /**
   * Procesa transcripci√≥n con un modelo espec√≠fico
   * @param {string} transcription - Transcripci√≥n m√©dica
   * @param {string} prompt - Prompt generado
   * @param {string} modelName - Nombre del modelo a usar
   * @param {Object} options - Opciones de procesamiento
   * @returns {Promise<Object>} Respuesta del modelo
   */
  async processWithModel(transcription, prompt, modelName, options = {}) {
    try {
      // Configurar modelo seleccionado
      const modelConfig = this.getModelConfiguration(modelName);
      
      // Obtener instancia del modelo
      const model = this.vertexAI.getGenerativeModel({
        model: modelName,
        generationConfig: modelConfig.generationConfig,
        safetySettings: modelConfig.safetySettings
      });

      // Procesar con el modelo
      const startTime = Date.now();
      
      logger.info('üîÑ ENVIANDO PROMPT AL MODELO:', {
        modelo: modelName,
        longitudTranscripcion: transcription.length,
        longitudPrompt: prompt.length,
        promptPreview: prompt.substring(0, 200) + '...',
        promptType: typeof prompt
      });

      // Asegurar que el prompt sea string y est√© bien formateado
      const promptText = typeof prompt === 'string' ? prompt : JSON.stringify(prompt);
      
      const result = await model.generateContent(promptText);
      const processingTime = (Date.now() - startTime) / 1000;

      // üîç PASO 2: LOGGEAR RESPUESTA CRUDA DE VERTEX AI
      // CR√çTICO: Logging exhaustivo ANTES del parsing para debugging
      logger.info('üîç RESPUESTA CRUDA COMPLETA DE VERTEX AI:', {
        modelo: modelName,
        tiempoProcesamiento: `${processingTime}s`,
        resultCompleto: JSON.stringify(result, null, 2),
        responseCompleto: JSON.stringify(result.response, null, 2),
        candidatesLength: result.response?.candidates?.length || 0,
        hasResponse: !!result.response,
        hasCandidates: !!result.response?.candidates,
        timestamp: new Date().toISOString()
      });

      // üîß NUEVA VALIDACI√ìN ROBUSTA CON M√öLTIPLES ESTRATEGIAS
      let extractedText = null;
      
      // ESTRATEGIA 1: Estructura est√°ndar de Vertex AI
      try {
        const response = result.response;
        
        if (!response) {
          throw new Error('Respuesta de Vertex AI est√° vac√≠a');
        }

        if (response.candidates && Array.isArray(response.candidates) && response.candidates.length > 0) {
          const candidate = response.candidates[0];
          
          if (candidate.content && candidate.content.parts && Array.isArray(candidate.content.parts) && candidate.content.parts.length > 0) {
            const part = candidate.content.parts[0];
            
            if (part.text) {
              extractedText = part.text;
              logger.info('‚úÖ TEXTO EXTRA√çDO CON ESTRUCTURA EST√ÅNDAR');
            }
          }
        }
      } catch (standardError) {
        logger.warn('‚ö†Ô∏è ESTRUCTURA EST√ÅNDAR FALL√ì:', standardError.message);
      }

      // ESTRATEGIA 2: Buscar texto en cualquier parte de la respuesta
      if (!extractedText) {
        try {
          const responseString = JSON.stringify(result);
          
          // Buscar patrones de texto en la respuesta
          const textPatterns = [
            /"text":\s*"([^"]+)"/,
            /"content":\s*"([^"]+)"/,
            /"parts":\s*\[\s*{\s*"text":\s*"([^"]+)"/
          ];
          
          for (const pattern of textPatterns) {
            const match = responseString.match(pattern);
            if (match && match[1]) {
              extractedText = match[1].replace(/\\n/g, '\n').replace(/\\"/g, '"');
              logger.info('‚úÖ TEXTO EXTRA√çDO CON PATR√ìN ALTERNATIVO');
              break;
            }
          }
        } catch (patternError) {
          logger.warn('‚ö†Ô∏è B√öSQUEDA DE PATRONES FALL√ì:', patternError.message);
        }
      }

      // ESTRATEGIA 3: Extraer de cualquier propiedad que contenga texto
      if (!extractedText) {
        try {
          const extractTextFromObject = (obj, depth = 0) => {
            if (depth > 5) return null; // Evitar recursi√≥n infinita
            
            if (typeof obj === 'string' && obj.length > 50) {
              // Si es un string largo, probablemente es la respuesta
              return obj;
            }
            
            if (typeof obj === 'object' && obj !== null) {
              for (const [key, value] of Object.entries(obj)) {
                if (key.toLowerCase().includes('text') || key.toLowerCase().includes('content')) {
                  const result = extractTextFromObject(value, depth + 1);
                  if (result) return result;
                }
              }
              
              // Buscar en todas las propiedades
              for (const value of Object.values(obj)) {
                const result = extractTextFromObject(value, depth + 1);
                if (result) return result;
              }
            }
            
            return null;
          };
          
          extractedText = extractTextFromObject(result);
          if (extractedText) {
            logger.info('‚úÖ TEXTO EXTRA√çDO CON B√öSQUEDA RECURSIVA');
          }
        } catch (recursiveError) {
          logger.warn('‚ö†Ô∏è B√öSQUEDA RECURSIVA FALL√ì:', recursiveError.message);
        }
      }

      // ESTRATEGIA 4: Fallback - Generar respuesta b√°sica
      if (!extractedText) {
        logger.error('‚ùå NO SE PUDO EXTRAER TEXTO DE VERTEX AI - USANDO FALLBACK');
        
        // Generar respuesta de fallback basada en la transcripci√≥n
        extractedText = this._generateFallbackResponse(transcription, modelName);
      }

      // üîç PASO 2: LOGGING DETALLADO DEL TEXTO EXTRA√çDO
      logger.info('‚úÖ TEXTO EXTRA√çDO EXITOSAMENTE DE VERTEX AI:', {
        modelo: modelName,
        tiempoProcesamiento: `${processingTime}s`,
        longitudRespuesta: extractedText.length,
        textoCompleto: extractedText, // CR√çTICO: Todo el texto para debugging
        textoPreview: extractedText.substring(0, 500) + (extractedText.length > 500 ? '...' : ''),
        contieneBrackets: extractedText.includes('{') && extractedText.includes('}'),
        contieneJsonBlock: extractedText.includes('```json'),
        primerosCaracteres: extractedText.substring(0, 50),
        ultimosCaracteres: extractedText.substring(Math.max(0, extractedText.length - 50)),
        timestamp: new Date().toISOString()
      });

      return {
        text: extractedText,
        modelUsed: modelName,
        processingTime: processingTime,
        metadata: {
          timestamp: new Date().toISOString(),
          projectId: this.projectId,
          location: this.location,
          inputLength: transcription.length,
          outputLength: extractedText.length
        }
      };

    } catch (error) {
      logger.error('‚ùå ERROR PROCESANDO CON MODELO:', {
        modelo: modelName,
        error: error.message
      });

      // Analizar si se debe reintentar con modelo diferente
      if (this.shouldRetryWithDifferentModel(error)) {
        logger.info('üîÑ REINTENTANDO CON MODELO ALTERNATIVO...');
        
        const fallbackModel = this.getFallbackModel(modelName);
        if (fallbackModel !== modelName) {
          return await this.processWithModel(transcription, prompt, fallbackModel, options);
        }
      }

      throw error;
    }
  }

  /**
   * Genera respuesta de fallback cuando Vertex AI falla
   * @param {string} transcription - Transcripci√≥n original
   * @param {string} modelName - Nombre del modelo que fall√≥
   * @returns {string} Respuesta de fallback en formato JSON
   */
  _generateFallbackResponse(transcription, modelName) {
    logger.info('üõ°Ô∏è GENERANDO RESPUESTA DE FALLBACK');
    
    // An√°lisis b√°sico de la transcripci√≥n para generar alertas
    const hasPain = /dolor|molestia|disconfort/i.test(transcription);
    const hasEmergency = /emergencia|urgencia|grave|cr√≠tico/i.test(transcription);
    const hasCardiac = /coraz√≥n|cardiaco|tor√°cico|pecho/i.test(transcription);
    const hasNeurological = /cabeza|neurol√≥gico|mareo|desmayo/i.test(transcription);
    
    const fallbackResponse = {
      warnings: [],
      suggestions: [],
      soap_analysis: {
        subjective_completeness: 50,
        objective_completeness: 30,
        assessment_quality: 40,
        plan_appropriateness: 35,
        overall_quality: 40,
        missing_elements: ['An√°lisis completo no disponible - Fallback activado']
      },
      session_quality: {
        communication_score: 70,
        clinical_thoroughness: 50,
        patient_engagement: 60,
        professional_standards: 75,
        areas_for_improvement: ['Sistema de an√°lisis temporalmente no disponible']
      }
    };

    // Agregar warnings basados en an√°lisis b√°sico
    if (hasEmergency) {
      fallbackResponse.warnings.push({
        id: 'fallback_emergency',
        severity: 'HIGH',
        category: 'system_fallback',
        title: 'An√°lisis de Emergencia Requerido',
        description: 'Se detectaron t√©rminos de emergencia en la transcripci√≥n. Se requiere evaluaci√≥n m√©dica inmediata.',
        recommendation: 'Evaluar paciente de forma urgente y considerar derivaci√≥n a emergencias.',
        evidence: 'T√©rminos de emergencia detectados en transcripci√≥n'
      });
    }

    if (hasCardiac) {
      fallbackResponse.warnings.push({
        id: 'fallback_cardiac',
        severity: 'HIGH',
        category: 'clinical_alert',
        title: 'Posible S√≠ntoma Card√≠aco',
        description: 'Se detectaron referencias a s√≠ntomas card√≠acos. Requiere evaluaci√≥n cardiol√≥gica.',
        recommendation: 'Realizar evaluaci√≥n cardiol√≥gica completa y considerar ECG.',
        evidence: 'Referencias card√≠acas detectadas en transcripci√≥n'
      });
    }

    if (hasNeurological) {
      fallbackResponse.warnings.push({
        id: 'fallback_neurological',
        severity: 'MEDIUM',
        category: 'clinical_alert',
        title: 'S√≠ntomas Neurol√≥gicos Detectados',
        description: 'Se detectaron s√≠ntomas neurol√≥gicos que requieren evaluaci√≥n especializada.',
        recommendation: 'Considerar evaluaci√≥n neurol√≥gica y estudios complementarios.',
        evidence: 'S√≠ntomas neurol√≥gicos detectados en transcripci√≥n'
      });
    }

    // Agregar sugerencias b√°sicas
    fallbackResponse.suggestions.push({
      id: 'fallback_reassessment',
      type: 'system_recommendation',
      title: 'Reevaluaci√≥n Completa Requerida',
      description: 'El sistema de an√°lisis no est√° disponible. Se requiere evaluaci√≥n cl√≠nica manual completa.',
      rationale: 'Fallback activado debido a problema t√©cnico con Vertex AI',
      priority: 'HIGH'
    });

    return JSON.stringify(fallbackResponse, null, 2);
  }

  /**
   * Obtiene configuraci√≥n espec√≠fica para cada modelo
   * @param {string} modelName - Nombre del modelo
   * @returns {Object} Configuraci√≥n del modelo
   */
  getModelConfiguration(modelName) {
    const configurations = {
      'gemini-2.5-pro': {
        generationConfig: {
          temperature: 0.1,
          topK: 40,
          topP: 0.95,
          maxOutputTokens: 8192,
          candidateCount: 1
        },
        safetySettings: [
          { category: 'HARM_CATEGORY_HARASSMENT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
          { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
          { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
          { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' }
        ]
      },
      'gemini-2.5-flash': {
        generationConfig: {
          temperature: 0.2,
          topK: 32,
          topP: 0.9,
          maxOutputTokens: 4096,
          candidateCount: 1
        },
        safetySettings: [
          { category: 'HARM_CATEGORY_HARASSMENT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
          { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
          { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
          { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' }
        ]
      },
      'gemini-2.0-flash': {
        generationConfig: {
          temperature: 0.3,
          topK: 24,
          topP: 0.85,
          maxOutputTokens: 2048,
          candidateCount: 1
        },
        safetySettings: [
          { category: 'HARM_CATEGORY_HARASSMENT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
          { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
          { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' },
          { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_MEDIUM_AND_ABOVE' }
        ]
      }
    };

    return configurations[modelName] || configurations['gemini-2.5-flash'];
  }

  /**
   * Determina si se debe reintentar con un modelo diferente
   * @param {Error} error - Error ocurrido
   * @returns {boolean} Si se debe reintentar
   */
  shouldRetryWithDifferentModel(error) {
    const retryableErrors = [
      'RESOURCE_EXHAUSTED',
      'QUOTA_EXCEEDED',
      'MODEL_NOT_AVAILABLE',
      'INVALID_ARGUMENT'
    ];

    return retryableErrors.some(errorType => 
      error.message.includes(errorType) || error.code === errorType
    );
  }

  /**
   * Obtiene modelo de fallback
   * @param {string} currentModel - Modelo actual que fall√≥
   * @returns {string} Modelo de fallback
   */
  getFallbackModel(currentModel) {
    const fallbackChain = {
      'gemini-2.5-pro': 'gemini-2.5-flash',
      'gemini-2.5-flash': 'gemini-2.0-flash',
      'gemini-2.0-flash': 'gemini-2.5-flash'
    };

    return fallbackChain[currentModel] || 'gemini-2.5-flash';
  }

  /**
   * Obtiene informaci√≥n detallada del modelo actual
   * @returns {Object} Informaci√≥n del modelo
   */
  getModelInfo() {
    return {
      projectId: this.projectId,
      location: this.location,
      defaultModel: this.defaultModel,
      availableModels: this.modelSelector.getAvailableModels(),
      optimizationEnabled: true,
      timestamp: new Date().toISOString()
    };
  }

  /**
   * Obtiene estad√≠sticas de uso y costos
   * @returns {Object} Estad√≠sticas de optimizaci√≥n
   */
  getOptimizationStats() {
    return {
      modelsAvailable: Object.keys(this.modelSelector.getAvailableModels()),
      costOptimization: 'Habilitado',
      selectionStrategy: 'Basado en complejidad autom√°tica',
      maxSavings: 'Hasta 22.5x vs modelo premium'
    };
  }
}

module.exports = VertexAIClient; 